{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-minister",
   "metadata": {},
   "source": [
    "# Best Models With Nutritional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-float",
   "metadata": {},
   "source": [
    "## Common Part\n",
    "This part has the functions that are needed to perform the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Src/')\n",
    "from data_modificado import * \n",
    "from train_2 import * \n",
    "from transfer_learning import * \n",
    "from transfer_learning_FI import * \n",
    "from test_functions import *\n",
    "from layers import *\n",
    "from utils import *\n",
    "from loss import *\n",
    "from metric import *\n",
    "from results import *\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import itertools as it\n",
    "\n",
    "def read_df(\n",
    "              metadata_names=['age','Temperature','Precipitation3Days'],\n",
    "              random_state=42,\n",
    "              otu_filename='../Datasets/otu_table_all_80.csv',\n",
    "              metadata_filename='../Datasets/metadata_table_all_80.csv'):\n",
    "    otu = pd.read_csv(otu_filename, index_col=0, header=None).T\n",
    "    #print(otu.head())\n",
    "    otu = otu.set_index('otuids')\n",
    "    otu = otu.astype('int32')\n",
    "    metadata = pd.read_csv(metadata_filename)\n",
    "    #print(metadata.head())\n",
    "    metadata = metadata.set_index('X.SampleID')\n",
    "    metadata.head()\n",
    "    domain = metadata[metadata_names]\n",
    "    df = pd.concat([otu, domain], axis=1, sort=True, join='outer')\n",
    "    df_microbioma = df[otu.columns]\n",
    "    df_domain = df[domain.columns]\n",
    "    df_domain.head()\n",
    "    df_microbioma_train, df_microbioma_no_train, df_domain_train, df_domain_no_train = \\\n",
    "        train_test_split(df_microbioma, df_domain, test_size=0.1, random_state=random_state)\n",
    "    # Transfer learning subset\n",
    "    df_microbioma_test, df_microbioma_transfer_learning, df_domain_test, df_domain_transfer_learning = \\\n",
    "        train_test_split(df_microbioma_no_train, df_domain_no_train, test_size=0.1, random_state=random_state)\n",
    "    df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test = \\\n",
    "        train_test_split(df_microbioma_transfer_learning, df_domain_transfer_learning, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    return df_microbioma_train, df_microbioma_test, df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, df_domain_train, df_domain_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test, otu.columns, domain.columns\n",
    "\n",
    "def train_kfold_mod(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                batch_size, epochs, train_callbacks):\n",
    "    all_models = model_fn()\n",
    "    model, encoder_bioma, encoder_domain, decoder_bioma = all_models\n",
    "    metrics_prefix = None\n",
    "    if encoder_bioma is not None and encoder_domain is not None:\n",
    "        x_train = (m_train, d_train)\n",
    "        y_train = (m_train, m_train, z_train)\n",
    "        x_test = (m_test, d_test)\n",
    "        y_test = (m_test, m_test, z_test)\n",
    "    elif encoder_bioma is not None:\n",
    "        x_train = m_train\n",
    "        y_train = m_train\n",
    "        x_test = m_test\n",
    "        y_test = m_test\n",
    "        metrics_prefix = 'bioma'\n",
    "    elif encoder_domain is not None:\n",
    "        x_train = d_train\n",
    "        y_train = m_train\n",
    "        x_test = d_test\n",
    "        y_test = m_test\n",
    "        metrics_prefix = 'domain'\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(5000).batch(\n",
    "        batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    r = model.fit(train_dataset,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=val_dataset,\n",
    "                  callbacks=train_callbacks,\n",
    "                  verbose=0)\n",
    "    if metrics_prefix is not None:\n",
    "        old_keys = r.history\n",
    "        r.history = {}\n",
    "        for k, v in old_keys.items():\n",
    "            if k == 'loss' or k == 'val_loss':\n",
    "                new_key = k\n",
    "            elif k.startswith('val_'):\n",
    "                new_key = 'val_{}_{}'.format(metrics_prefix, k[4:])\n",
    "            else:\n",
    "                new_key = '{}_{}'.format(metrics_prefix, k)\n",
    "            r.history[new_key] = v\n",
    "    del val_dataset\n",
    "    del train_dataset\n",
    "    del x_train\n",
    "    del y_train\n",
    "    del x_test\n",
    "    del y_test\n",
    "    return r, all_models\n",
    "\n",
    "def train_2(model_fn,\n",
    "          data_microbioma,\n",
    "          data_domain,\n",
    "          latent_space=10,\n",
    "          folds=5,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          learning_rate_scheduler=ExpDecayScheluder(),\n",
    "          random_seed=347,\n",
    "          verbose=0):\n",
    "    data_zeros_latent = np.zeros((data_microbioma.shape[0], latent_space), dtype=data_microbioma.dtype)\n",
    "    results = []\n",
    "    models = []\n",
    "    train_callbacks = [\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=epochs + 1, restore_best_weights=True)]\n",
    "    if verbose >= 0:\n",
    "        train_callbacks += [TqdmCallback(verbose=verbose)]\n",
    "    if learning_rate_scheduler is not None:\n",
    "        train_callbacks += [learning_rate_scheduler.make()]\n",
    "\n",
    "    if folds <= 1:\n",
    "        m_train, m_test = data_microbioma, data_microbioma\n",
    "        d_train, d_test = data_domain, data_domain\n",
    "        z_train, z_test = data_zeros_latent, data_zeros_latent\n",
    "        tf.random.set_seed(random_seed)\n",
    "        r, m = train_kfold(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                           batch_size, epochs, train_callbacks)\n",
    "        results.append(r)\n",
    "        models.append(m)\n",
    "\n",
    "    else:\n",
    "        kf = KFold(n_splits=folds, random_state=random_seed, shuffle=True)\n",
    "        tf.random.set_seed(random_seed)\n",
    "\n",
    "        for train_index, test_index in kf.split(data_microbioma):\n",
    "            m_train, m_test = data_microbioma[train_index], data_microbioma[test_index]\n",
    "            if data_domain is None:\n",
    "                d_train, d_test = None, None\n",
    "            else:\n",
    "                d_train, d_test = data_domain[train_index], data_domain[test_index]\n",
    "            z_train, z_test = data_zeros_latent[train_index], data_zeros_latent[test_index]\n",
    "            r, m = train_kfold_mod(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                               batch_size, epochs, train_callbacks)\n",
    "            results.append(r)\n",
    "            models.append(m)\n",
    "    return results, models\n",
    "\n",
    "def perform_experiment_2_mod(cv_folds, epochs, batch_size, learning_rate, optimizer,\n",
    "                       learning_rate_scheduler, input_transform, output_transform,\n",
    "                       reconstruction_loss, latent_space, layers,\n",
    "                       activation, activation_latent,\n",
    "                       data_microbioma_train, data_domain_train,\n",
    "                       show_results=True, device='/CPU:0'): #Show results cambiado de False  aTrue\n",
    "    if input_transform is not None:\n",
    "        input_transform = input_transform()\n",
    "    #----------    \n",
    "    if output_transform is not None:\n",
    "        output_transform = output_transform()\n",
    "    #----------      \n",
    "    if reconstruction_loss.__class__.__name__ == 'MakeLoss':\n",
    "        reconstruction_loss = reconstruction_loss.make()\n",
    "    else:\n",
    "        reconstruction_loss = reconstruction_loss()\n",
    "    domain_layers = [l // 16 for l in layers] \n",
    "    bioma_autoencoder = \" -> \".join([\"b\"] +\n",
    "                                    [str(l) for l in layers] +\n",
    "                                    [str(latent_space)] +\n",
    "                                    [str(l) for l in reversed(layers)] +\n",
    "                                    [\"b\"])\n",
    "    #---------- \n",
    "    \n",
    "    if data_domain_train is not None:\n",
    "        domain_autoencoder = \" -> \".join([\"d\"] +\n",
    "                                     [str(l) for l in domain_layers] +\n",
    "                                     [str(latent_space)] +\n",
    "                                     [str(l) for l in reversed(layers)] +\n",
    "                                     [\"b\"])\n",
    "        \n",
    "    else: \n",
    "        domain_autoencoder = \" \"\n",
    "    #---------- \n",
    "    in_transform_name = input_transform.__class__.__name__ if input_transform else \"none\"\n",
    "    out_transform_name = output_transform.__class__.__name__ if output_transform else \"none\"\n",
    "    lr_scheduler_text = learning_rate_scheduler[\n",
    "        1] if learning_rate_scheduler is not None else \"none\"\n",
    "    lr_text = learning_rate if learning_rate_scheduler is not None else \"constant = {}\".format(\n",
    "        learning_rate)\n",
    "    learning_rate_scheduler = learning_rate_scheduler[\n",
    "        0] if learning_rate_scheduler is not None else None\n",
    "    optimizer = optimizer(learning_rate=learning_rate)\n",
    "    #---------- \n",
    "    experiment_parameters = [\n",
    "        (\"Input transform\", in_transform_name),\n",
    "        (\"Output transform\", out_transform_name),\n",
    "        (\"Reconstruction Loss\", reconstruction_loss.__class__.__name__),\n",
    "        (\"Latent Space\", latent_space),\n",
    "        (\"Bioma Autoencoder\", bioma_autoencoder),\n",
    "        (\"Domain Autoencoder\", domain_autoencoder),\n",
    "        (\"Activation Encoder\", activation),\n",
    "        (\"Activation Decoder\", activation),\n",
    "        (\"Activation Latent\", activation_latent),\n",
    "        (\"CV folds\", cv_folds),\n",
    "        (\"Epochs\", epochs),\n",
    "        (\"Batch Size\", batch_size),\n",
    "        (\"Learning Rate Scheduler\", lr_scheduler_text),\n",
    "        (\"Learning Rate\", lr_text),\n",
    "        (\"Optimizer\", optimizer.__class__.__name__),\n",
    "    ]\n",
    "    #----------  \n",
    "    if show_results:\n",
    "        md_text = \"\"\n",
    "        md_text += \"| Parameter             | Value         |\\n\"\n",
    "        md_text += \"|:----------------------|:--------------|\\n\"\n",
    "        for n, v in experiment_parameters:\n",
    "            md_text += \"| {} | {} |\\n\".format(n, v)\n",
    "\n",
    "        display(Markdown(md_text))\n",
    "    #------------\n",
    "    def create_model(print_data=False):\n",
    "        bioma_shape=data_microbioma_train.shape[1]\n",
    "        \n",
    "        if data_domain_train is not None:\n",
    "            domain_shape=data_domain_train.shape[1]\n",
    "        else:\n",
    "            domain_shape=None\n",
    "        models = autoencoder(bioma_shape=bioma_shape,\n",
    "                             domain_shape=domain_shape,\n",
    "                             output_shape=bioma_shape,\n",
    "                             latent_space=latent_space,\n",
    "                             bioma_layers=layers, \n",
    "                             domain_layers=domain_layers,\n",
    "                             input_transform=input_transform,\n",
    "                             output_transform=output_transform,\n",
    "                             activation_function_encoder=activation,\n",
    "                             activation_function_decoder=activation,\n",
    "                             activation_function_latent=activation_latent)\n",
    "\n",
    "        \n",
    "        model, encoder_bioma, encoder_domain, decoder_bioma = models\n",
    "\n",
    "        if print_data:\n",
    "            plot_models(model, encoder_bioma, encoder_domain, decoder_bioma)\n",
    "        compile_train(model,\n",
    "                      encoder_bioma=encoder_bioma,\n",
    "                      encoder_domain=encoder_domain,\n",
    "                      reconstruction_error=reconstruction_loss,\n",
    "                      encoded_comparison_error=losses.MeanAbsoluteError(),\n",
    "                      metrics=get_experiment_metrics(input_transform, output_transform),\n",
    "                      optimizer=optimizer)\n",
    "        return model, encoder_bioma, encoder_domain, decoder_bioma\n",
    "    #-----------\n",
    "    create_model(print_data=False)\n",
    "    #-----------\n",
    "    with tf.device(device):\n",
    "        results, models = train_2(create_model,\n",
    "                                data_microbioma_train,\n",
    "                                data_domain_train,\n",
    "                                latent_space=latent_space,\n",
    "                                folds=cv_folds,\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                learning_rate_scheduler=learning_rate_scheduler,\n",
    "                                verbose=-1)\n",
    "    #----------\n",
    "    validation_results = print_results(results, show_results=show_results)\n",
    "    if show_results:\n",
    "        display(Markdown(\"*************\"))\n",
    "\n",
    "    return experiment_parameters + validation_results, models, results\n",
    "\n",
    "#-----------------------------\n",
    "def save_predicted_otu_table_and_latent(pred,pred_latent,sample_names,otu_names,suffix=''):\n",
    "    df_otu = pd.DataFrame(pred, index=sample_names, columns=otu_names)\n",
    "    df_otu.T.to_csv('Results/otus_'+suffix+'.tsv', index=True, header=True, sep='\\t')\n",
    "\n",
    "    df_latent = pd.DataFrame(pred_latent, index=sample_names)\n",
    "    df_latent.T.to_csv('Results/latent_'+suffix+'.tsv', index=True, sep='\\t')\n",
    "    \n",
    "    return df_otu, df_latent\n",
    "\n",
    "#Compute metrics by OTU\n",
    "# Absolute abundance transformed to TSS (with epsilon=1E-6)\n",
    "def transform_to_rel_abundance(dataset):\n",
    "    epsilon=1E-6\n",
    "    sum_per_sample = dataset.sum(axis=1)\n",
    "    num_samples = sum_per_sample.shape\n",
    "    num_OTUs = np.shape(dataset)[-1] \n",
    "    sum_per_sample = sum_per_sample + (num_OTUs * epsilon)\n",
    "    dividend=dataset+epsilon\n",
    "    dataset_rel_abund = np.divide(dividend,sum_per_sample[:,None])\n",
    "    return dataset_rel_abund\n",
    "def compute_relative_squared_error(actual,pred_domain):\n",
    "    rse_otu=np.zeros(actual.shape[1],dtype=np.float32)\n",
    "    actual=actual.transpose()\n",
    "    pred=pred_domain.transpose()\n",
    "    for i, (act_otu,pred_otu) in enumerate(zip(actual,pred)):\n",
    "        mean_otu = act_otu.mean()\n",
    "        div_up=((pred_otu-act_otu)**2).sum()\n",
    "        div_down=((pred_otu-mean_otu)**2).sum()\n",
    "        rse_otu[i]=div_up/div_down\n",
    "    return rse_otu, np.sqrt(rse_otu)\n",
    "\n",
    "def save_errors_per_OTU(RSE,RRSE,otu_names,suffix=''):\n",
    "    df_RSE = pd.DataFrame(RSE, index=otu_names, columns=['RSE'])\n",
    "    df_RRSE = pd.DataFrame(RRSE, index=otu_names, columns=['RRSE'])\n",
    "    df_error = df_RSE.join(df_RRSE)\n",
    "    df_error.to_csv(suffix+'.tsv', index=True, header=True, sep='\\t')\n",
    "    \n",
    "    return df_error\n",
    "\n",
    "#-------------------------------\n",
    "def FI():\n",
    "    metric_results, _ = test_model_tl_noEnsemble_FI(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)\n",
    "    error_original = metric_results[\"BrayCurtis\"][0]\n",
    "    metricas = dict()\n",
    "    for i, variable in enumerate(nombres_metadatos):\n",
    "        df1 = df_domain_test\n",
    "        valores_BrayCurtis = []\n",
    "        for j in range(0,10,1):\n",
    "            df1[variable] = np.random.permutation(df_domain_test[variable].values)\n",
    "            data_domain_test_nueva = df1.to_numpy()\n",
    "            metric_results, _ = test_model_tl_noEnsemble_FI(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test_nueva)\n",
    "            #valores_BrayCurtis.append(metric_results[\"BrayCurtis\"][0]/error_original)\n",
    "            valores_BrayCurtis.append(metric_results[\"BrayCurtis\"][0]-error_original)\n",
    "        metricas[variable] = valores_BrayCurtis\n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(encoder, model_latent, name_type_model, taxonomical_rank, data_microbioma_test, df_microbioma_test):\n",
    "    encoder_biome = encoder\n",
    "    encoder_domain = model_latent\n",
    "\n",
    "    #run prediction test set from microbiome, i.e, reconstructed\n",
    "    # Input only domain (i.e. environmental features)\n",
    "    pred_latent_biome = encoder_biome.predict(data_microbioma_test)\n",
    "    pred_biome = decoder.predict(pred_latent_biome)\n",
    "\n",
    "    _, _ = save_predicted_otu_table_and_latent(pred_biome,pred_latent_biome,df_microbioma_test.index,df_microbioma_test.columns,'reconstAEfromBiome_'+name_type_model+\"_\"+taxonomical_rank)\n",
    "\n",
    "    #run prediction test set from domain, i.e., diet features\n",
    "    # Input only domain (i.e. environmental features)\n",
    "    pred_latent = encoder_domain.predict(data_domain_test)\n",
    "    pred_domain = decoder.predict(pred_latent)\n",
    "    df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,df_microbioma_test.index,df_microbioma_test.columns,'predFromDomain_'+name_type_model+\"_\"+taxonomical_rank)\n",
    "    \n",
    "    #--------------------\n",
    "    actual_array = transform_to_rel_abundance(data_microbioma_test)\n",
    "    RSE_perOTU, RRSE_perOTU  = compute_relative_squared_error(actual_array, pred_domain)\n",
    "\n",
    "    df_error_perOTU = save_errors_per_OTU(RSE_perOTU,RRSE_perOTU,df_microbioma_test.columns,'Results/errors_perOTU_'+name_type_model+\"_\"+taxonomical_rank)\n",
    "    \n",
    "    #-----------------\n",
    "    metrics = FI()\n",
    "    tabla_FI = pd.DataFrame.from_dict(metrics)\n",
    "    tabla_FI.to_csv(\"Results/FI_\"+name_type_model+'_'+taxonomical_rank+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-official",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "--------------------------\n",
    "# 41 variables Latent Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='sigmoid')(in_layer)\n",
    "    net = layers.Dense(64, activation='sigmoid')(net)\n",
    "    net = layers.Dense(32, activation='sigmoid')(net)\n",
    "    net = layers.Dense(16, activation='sigmoid')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='softmax')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-nursing",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)\n",
    "\n",
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False, #True show results training, False doe not show it\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"41Combined\", \"Specie\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-guitar",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-tennessee",
   "metadata": {},
   "source": [
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)\n",
    "\n",
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False, #True show results training, False doe not show it\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41Combined\", \"Genus\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-concrete",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41Combined\", \"Family\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-brunei",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "#nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41Combined\", \"Order\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-contest",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41Combined\", \"Class\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-administrator",
   "metadata": {},
   "source": [
    "------------------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41Combined\", \"Phylum\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-kazakhstan",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "--------------------------\n",
    "# 41 variables Latent OTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='softmax')(in_layer)\n",
    "    net = layers.Dense(64, activation='softmax')(net)\n",
    "    net = layers.Dense(32, activation='softmax')(net)\n",
    "    net = layers.Dense(16, activation='softmax')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-sampling",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41OTU\", \"Specie\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-commission",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41OTU\", \"Genus\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-hospital",
   "metadata": {},
   "source": [
    "----------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41OTU\", \"Family\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-pharmaceutical",
   "metadata": {},
   "source": [
    "----------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41OTU\", \"Order\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-patrol",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41OTU\", \"Class\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-intention",
   "metadata": {},
   "source": [
    "---------------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"41OTU\", \"Phylum\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-activation",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "--------------------------\n",
    "# 22 variables Latent Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='tanh')(in_layer)\n",
    "    net = layers.Dense(64, activation='tanh')(net)\n",
    "    net = layers.Dense(32, activation='tanh')(net)\n",
    "    net = layers.Dense(16, activation='tanh')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-observer",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22Combined\", \"Specie\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-running",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22Combined\", \"Genus\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-behalf",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-sunglasses",
   "metadata": {},
   "source": [
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22Combined\", \"Family\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-spending",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22Combined\", \"Order\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-priest",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22Combined\", \"Class\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-links",
   "metadata": {},
   "source": [
    "---------------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22Combined\", \"Phylum\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-supplement",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "--------------------------\n",
    "# 22 variables Latent OTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='sigmoid')(in_layer)\n",
    "    net = layers.Dense(64, activation='sigmoid')(net)\n",
    "    net = layers.Dense(32, activation='sigmoid')(net)\n",
    "    net = layers.Dense(16, activation='sigmoid')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-spiritual",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22OTU\", \"Specie\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-governor",
   "metadata": {},
   "source": [
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22OTU\", \"Genus\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-found",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='resultados_ana/nuevos_datos/arreglados/otu_table_Family.csv',metadata_filename='resultados_ana/datos_otus_metadatos_familia/metadatos_nutrientes_familia.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22OTU\", \"Family\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-pencil",
   "metadata": {},
   "source": [
    "------------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='resultados_ana/nuevos_datos/arreglados/otu_table_Order.csv',metadata_filename='resultados_ana/datos_otus_metadatos_orden/metadatos_nutrientes_orden.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22OTU\", \"Order\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-mumbai",
   "metadata": {},
   "source": [
    "----------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='resultados_ana/nuevos_datos/arreglados/otu_table_Class.csv',metadata_filename='resultados_ana/datos_otus_metadatos_clase/metadatos_nutrientes_clase.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22OTU\", \"Class\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-postcard",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='resultados_ana/nuevos_datos/arreglados/otu_table_Phylum.csv',metadata_filename='resultados_ana/datos_otus_metadatos_filo/metadatos_nutrientes_filo.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(encoder, model_latent, \"22OTU\", \"Phylum\", data_microbioma_test, df_microbioma_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
