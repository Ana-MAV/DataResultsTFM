{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "potential-february",
   "metadata": {},
   "source": [
    "# Best Models With Food Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-findings",
   "metadata": {},
   "source": [
    "## Common Part\n",
    "This part has the functions that are needed to perform the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Src/')\n",
    "from data_modificado import * \n",
    "from train_2 import * \n",
    "from transfer_learning import * \n",
    "from transfer_learning_FI import * \n",
    "from test_functions import *\n",
    "from layers import *\n",
    "from utils import *\n",
    "from loss import *\n",
    "from metric import *\n",
    "from results import *\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import itertools as it\n",
    "\n",
    "def read_df(\n",
    "              metadata_names=['age','Temperature','Precipitation3Days'],\n",
    "              random_state=42,\n",
    "              otu_filename='../Datasets/otu_table_all_80.csv',\n",
    "              metadata_filename='../Datasets/metadata_table_all_80.csv'):\n",
    "    otu = pd.read_csv(otu_filename, index_col=0, header=None).T\n",
    "    #print(otu.head())\n",
    "    otu = otu.set_index('otuids')\n",
    "    otu = otu.astype('int32')\n",
    "    metadata = pd.read_csv(metadata_filename)\n",
    "    #print(metadata.head())\n",
    "    metadata = metadata.set_index('X.SampleID')\n",
    "    metadata.head()\n",
    "    domain = metadata[metadata_names]\n",
    "    df = pd.concat([otu, domain], axis=1, sort=True, join='outer')\n",
    "    df_microbioma = df[otu.columns]\n",
    "    df_domain = df[domain.columns]\n",
    "    df_domain.head()\n",
    "    df_microbioma_train, df_microbioma_no_train, df_domain_train, df_domain_no_train = \\\n",
    "        train_test_split(df_microbioma, df_domain, test_size=0.1, random_state=random_state)\n",
    "    # Transfer learning subset\n",
    "    df_microbioma_test, df_microbioma_transfer_learning, df_domain_test, df_domain_transfer_learning = \\\n",
    "        train_test_split(df_microbioma_no_train, df_domain_no_train, test_size=0.1, random_state=random_state)\n",
    "    df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test = \\\n",
    "        train_test_split(df_microbioma_transfer_learning, df_domain_transfer_learning, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    return df_microbioma_train, df_microbioma_test, df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, df_domain_train, df_domain_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test, otu.columns, domain.columns\n",
    "\n",
    "def train_kfold_mod(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                batch_size, epochs, train_callbacks):\n",
    "    all_models = model_fn()\n",
    "    model, encoder_bioma, encoder_domain, decoder_bioma = all_models\n",
    "    metrics_prefix = None\n",
    "    if encoder_bioma is not None and encoder_domain is not None:\n",
    "        x_train = (m_train, d_train)\n",
    "        y_train = (m_train, m_train, z_train)\n",
    "        x_test = (m_test, d_test)\n",
    "        y_test = (m_test, m_test, z_test)\n",
    "    elif encoder_bioma is not None:\n",
    "        x_train = m_train\n",
    "        y_train = m_train\n",
    "        x_test = m_test\n",
    "        y_test = m_test\n",
    "        metrics_prefix = 'bioma'\n",
    "    elif encoder_domain is not None:\n",
    "        x_train = d_train\n",
    "        y_train = m_train\n",
    "        x_test = d_test\n",
    "        y_test = m_test\n",
    "        metrics_prefix = 'domain'\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(5000).batch(\n",
    "        batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    r = model.fit(train_dataset,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=val_dataset,\n",
    "                  callbacks=train_callbacks,\n",
    "                  verbose=0)\n",
    "    if metrics_prefix is not None:\n",
    "        old_keys = r.history\n",
    "        r.history = {}\n",
    "        for k, v in old_keys.items():\n",
    "            if k == 'loss' or k == 'val_loss':\n",
    "                new_key = k\n",
    "            elif k.startswith('val_'):\n",
    "                new_key = 'val_{}_{}'.format(metrics_prefix, k[4:])\n",
    "            else:\n",
    "                new_key = '{}_{}'.format(metrics_prefix, k)\n",
    "            r.history[new_key] = v\n",
    "    del val_dataset\n",
    "    del train_dataset\n",
    "    del x_train\n",
    "    del y_train\n",
    "    del x_test\n",
    "    del y_test\n",
    "    return r, all_models\n",
    "\n",
    "def train_2(model_fn,\n",
    "          data_microbioma,\n",
    "          data_domain,\n",
    "          latent_space=10,\n",
    "          folds=5,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          learning_rate_scheduler=ExpDecayScheluder(),\n",
    "          random_seed=347,\n",
    "          verbose=0):\n",
    "    data_zeros_latent = np.zeros((data_microbioma.shape[0], latent_space), dtype=data_microbioma.dtype)\n",
    "    results = []\n",
    "    models = []\n",
    "    train_callbacks = [\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=epochs + 1, restore_best_weights=True)]\n",
    "    if verbose >= 0:\n",
    "        train_callbacks += [TqdmCallback(verbose=verbose)]\n",
    "    if learning_rate_scheduler is not None:\n",
    "        train_callbacks += [learning_rate_scheduler.make()]\n",
    "\n",
    "    if folds <= 1:\n",
    "        m_train, m_test = data_microbioma, data_microbioma\n",
    "        d_train, d_test = data_domain, data_domain\n",
    "        z_train, z_test = data_zeros_latent, data_zeros_latent\n",
    "        tf.random.set_seed(random_seed)\n",
    "        r, m = train_kfold(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                           batch_size, epochs, train_callbacks)\n",
    "        results.append(r)\n",
    "        models.append(m)\n",
    "\n",
    "    else:\n",
    "        kf = KFold(n_splits=folds, random_state=random_seed, shuffle=True)\n",
    "        tf.random.set_seed(random_seed)\n",
    "\n",
    "        for train_index, test_index in kf.split(data_microbioma):\n",
    "            m_train, m_test = data_microbioma[train_index], data_microbioma[test_index]\n",
    "            if data_domain is None:\n",
    "                d_train, d_test = None, None\n",
    "            else:\n",
    "                d_train, d_test = data_domain[train_index], data_domain[test_index]\n",
    "            z_train, z_test = data_zeros_latent[train_index], data_zeros_latent[test_index]\n",
    "            r, m = train_kfold_mod(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                               batch_size, epochs, train_callbacks)\n",
    "            results.append(r)\n",
    "            models.append(m)\n",
    "    return results, models\n",
    "\n",
    "def perform_experiment_2_mod(cv_folds, epochs, batch_size, learning_rate, optimizer,\n",
    "                       learning_rate_scheduler, input_transform, output_transform,\n",
    "                       reconstruction_loss, latent_space, layers,\n",
    "                       activation, activation_latent,\n",
    "                       data_microbioma_train, data_domain_train,\n",
    "                       show_results=True, device='/CPU:0'): #Show results cambiado de False  aTrue\n",
    "    if input_transform is not None:\n",
    "        input_transform = input_transform()\n",
    "    #----------    \n",
    "    if output_transform is not None:\n",
    "        output_transform = output_transform()\n",
    "    #----------      \n",
    "    if reconstruction_loss.__class__.__name__ == 'MakeLoss':\n",
    "        reconstruction_loss = reconstruction_loss.make()\n",
    "    else:\n",
    "        reconstruction_loss = reconstruction_loss()\n",
    "    domain_layers = [l // 16 for l in layers] \n",
    "    bioma_autoencoder = \" -> \".join([\"b\"] +\n",
    "                                    [str(l) for l in layers] +\n",
    "                                    [str(latent_space)] +\n",
    "                                    [str(l) for l in reversed(layers)] +\n",
    "                                    [\"b\"])\n",
    "    #---------- \n",
    "    \n",
    "    if data_domain_train is not None:\n",
    "        domain_autoencoder = \" -> \".join([\"d\"] +\n",
    "                                     [str(l) for l in domain_layers] +\n",
    "                                     [str(latent_space)] +\n",
    "                                     [str(l) for l in reversed(layers)] +\n",
    "                                     [\"b\"])\n",
    "        \n",
    "    else: \n",
    "        domain_autoencoder = \" \"\n",
    "    #---------- \n",
    "    in_transform_name = input_transform.__class__.__name__ if input_transform else \"none\"\n",
    "    out_transform_name = output_transform.__class__.__name__ if output_transform else \"none\"\n",
    "    lr_scheduler_text = learning_rate_scheduler[\n",
    "        1] if learning_rate_scheduler is not None else \"none\"\n",
    "    lr_text = learning_rate if learning_rate_scheduler is not None else \"constant = {}\".format(\n",
    "        learning_rate)\n",
    "    learning_rate_scheduler = learning_rate_scheduler[\n",
    "        0] if learning_rate_scheduler is not None else None\n",
    "    optimizer = optimizer(learning_rate=learning_rate)\n",
    "    #---------- \n",
    "    experiment_parameters = [\n",
    "        (\"Input transform\", in_transform_name),\n",
    "        (\"Output transform\", out_transform_name),\n",
    "        (\"Reconstruction Loss\", reconstruction_loss.__class__.__name__),\n",
    "        (\"Latent Space\", latent_space),\n",
    "        (\"Bioma Autoencoder\", bioma_autoencoder),\n",
    "        (\"Domain Autoencoder\", domain_autoencoder),\n",
    "        (\"Activation Encoder\", activation),\n",
    "        (\"Activation Decoder\", activation),\n",
    "        (\"Activation Latent\", activation_latent),\n",
    "        (\"CV folds\", cv_folds),\n",
    "        (\"Epochs\", epochs),\n",
    "        (\"Batch Size\", batch_size),\n",
    "        (\"Learning Rate Scheduler\", lr_scheduler_text),\n",
    "        (\"Learning Rate\", lr_text),\n",
    "        (\"Optimizer\", optimizer.__class__.__name__),\n",
    "    ]\n",
    "    #----------  \n",
    "    if show_results:\n",
    "        md_text = \"\"\n",
    "        md_text += \"| Parameter             | Value         |\\n\"\n",
    "        md_text += \"|:----------------------|:--------------|\\n\"\n",
    "        for n, v in experiment_parameters:\n",
    "            md_text += \"| {} | {} |\\n\".format(n, v)\n",
    "\n",
    "        display(Markdown(md_text))\n",
    "    #------------\n",
    "    def create_model(print_data=False):\n",
    "        bioma_shape=data_microbioma_train.shape[1]\n",
    "        \n",
    "        if data_domain_train is not None:\n",
    "            domain_shape=data_domain_train.shape[1]\n",
    "        else:\n",
    "            domain_shape=None\n",
    "        models = autoencoder(bioma_shape=bioma_shape,\n",
    "                             domain_shape=domain_shape,\n",
    "                             output_shape=bioma_shape,\n",
    "                             latent_space=latent_space,\n",
    "                             bioma_layers=layers, \n",
    "                             domain_layers=domain_layers,\n",
    "                             input_transform=input_transform,\n",
    "                             output_transform=output_transform,\n",
    "                             activation_function_encoder=activation,\n",
    "                             activation_function_decoder=activation,\n",
    "                             activation_function_latent=activation_latent)\n",
    "\n",
    "        \n",
    "        model, encoder_bioma, encoder_domain, decoder_bioma = models\n",
    "\n",
    "        if print_data:\n",
    "            plot_models(model, encoder_bioma, encoder_domain, decoder_bioma)\n",
    "        compile_train(model,\n",
    "                      encoder_bioma=encoder_bioma,\n",
    "                      encoder_domain=encoder_domain,\n",
    "                      reconstruction_error=reconstruction_loss,\n",
    "                      encoded_comparison_error=losses.MeanAbsoluteError(),\n",
    "                      metrics=get_experiment_metrics(input_transform, output_transform),\n",
    "                      optimizer=optimizer)\n",
    "        return model, encoder_bioma, encoder_domain, decoder_bioma\n",
    "    #-----------\n",
    "    create_model(print_data=False)\n",
    "    #-----------\n",
    "    with tf.device(device):\n",
    "        results, models = train_2(create_model,\n",
    "                                data_microbioma_train,\n",
    "                                data_domain_train,\n",
    "                                latent_space=latent_space,\n",
    "                                folds=cv_folds,\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                learning_rate_scheduler=learning_rate_scheduler,\n",
    "                                verbose=-1)\n",
    "    #----------\n",
    "    validation_results = print_results(results, show_results=show_results)\n",
    "    if show_results:\n",
    "        display(Markdown(\"*************\"))\n",
    "\n",
    "    return experiment_parameters + validation_results, models, results\n",
    "\n",
    "#-----------------------------\n",
    "def save_predicted_otu_table_and_latent(pred,pred_latent,sample_names,otu_names,suffix=''):\n",
    "    df_otu = pd.DataFrame(pred, index=sample_names, columns=otu_names)\n",
    "    df_otu.T.to_csv('Results/otus_'+suffix+'.tsv', index=True, header=True, sep='\\t')\n",
    "\n",
    "    df_latent = pd.DataFrame(pred_latent, index=sample_names)\n",
    "    df_latent.T.to_csv('Results/latent_'+suffix+'.tsv', index=True, sep='\\t')\n",
    "    \n",
    "    return df_otu, df_latent\n",
    "\n",
    "#Compute metrics by OTU\n",
    "# Absolute abundance transformed to TSS (with epsilon=1E-6)\n",
    "def transform_to_rel_abundance(dataset):\n",
    "    epsilon=1E-6\n",
    "    sum_per_sample = dataset.sum(axis=1)\n",
    "    num_samples = sum_per_sample.shape\n",
    "    num_OTUs = np.shape(dataset)[-1] \n",
    "    sum_per_sample = sum_per_sample + (num_OTUs * epsilon)\n",
    "    dividend=dataset+epsilon\n",
    "    dataset_rel_abund = np.divide(dividend,sum_per_sample[:,None])\n",
    "    return dataset_rel_abund\n",
    "def compute_relative_squared_error(actual,pred_domain):\n",
    "    rse_otu=np.zeros(actual.shape[1],dtype=np.float32)\n",
    "    actual=actual.transpose()\n",
    "    pred=pred_domain.transpose()\n",
    "    for i, (act_otu,pred_otu) in enumerate(zip(actual,pred)):\n",
    "        mean_otu = act_otu.mean()\n",
    "        div_up=((pred_otu-act_otu)**2).sum()\n",
    "        div_down=((pred_otu-mean_otu)**2).sum()\n",
    "        rse_otu[i]=div_up/div_down\n",
    "    return rse_otu, np.sqrt(rse_otu)\n",
    "\n",
    "def save_errors_per_OTU(RSE,RRSE,otu_names,suffix=''):\n",
    "    df_RSE = pd.DataFrame(RSE, index=otu_names, columns=['RSE'])\n",
    "    df_RRSE = pd.DataFrame(RRSE, index=otu_names, columns=['RRSE'])\n",
    "    df_error = df_RSE.join(df_RRSE)\n",
    "    df_error.to_csv(suffix+'.tsv', index=True, header=True, sep='\\t')\n",
    "    \n",
    "    return df_error\n",
    "\n",
    "#-------------------------------\n",
    "def FI():\n",
    "    metric_results, _ = test_model_tl_noEnsemble_FI(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)\n",
    "    error_original = metric_results[\"BrayCurtis\"][0]\n",
    "    metricas = dict()\n",
    "    for i, variable in enumerate(nombres_metadatos):\n",
    "        df1 = df_domain_test\n",
    "        valores_BrayCurtis = []\n",
    "        for j in range(0,10,1):\n",
    "            df1[variable] = np.random.permutation(df_domain_test[variable].values)\n",
    "            data_domain_test_nueva = df1.to_numpy()\n",
    "            metric_results, _ = test_model_tl_noEnsemble_FI(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test_nueva)\n",
    "            #valores_BrayCurtis.append(metric_results[\"BrayCurtis\"][0]/error_original)\n",
    "            valores_BrayCurtis.append(metric_results[\"BrayCurtis\"][0]-error_original)\n",
    "        metricas[variable] = valores_BrayCurtis\n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(encoder, model_latent, name_type_model, taxonomical_rank, data_microbioma_test, df_microbioma_test):\n",
    "    encoder_biome = encoder\n",
    "    encoder_domain = model_latent\n",
    "\n",
    "    #run prediction test set from microbiome, i.e, reconstructed\n",
    "    # Input only domain (i.e. environmental features)\n",
    "    pred_latent_biome = encoder_biome.predict(data_microbioma_test)\n",
    "    pred_biome = decoder.predict(pred_latent_biome)\n",
    "\n",
    "    _, _ = save_predicted_otu_table_and_latent(pred_biome,pred_latent_biome,df_microbioma_test.index,df_microbioma_test.columns,'reconstAEfromBiome_'+name_type_model+\"_\"+taxonomical_rank)\n",
    "\n",
    "    #run prediction test set from domain, i.e., diet features\n",
    "    # Input only domain (i.e. environmental features)\n",
    "    pred_latent = encoder_domain.predict(data_domain_test)\n",
    "    pred_domain = decoder.predict(pred_latent)\n",
    "    df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,df_microbioma_test.index,df_microbioma_test.columns,'predFromDomain_'+name_type_model+\"_\"+taxonomical_rank)\n",
    "    \n",
    "    #--------------------\n",
    "    actual_array = transform_to_rel_abundance(data_microbioma_test)\n",
    "    RSE_perOTU, RRSE_perOTU  = compute_relative_squared_error(actual_array, pred_domain)\n",
    "\n",
    "    df_error_perOTU = save_errors_per_OTU(RSE_perOTU,RRSE_perOTU,df_microbioma_test.columns,'Results/errors_perOTU_'+name_type_model+\"_\"+taxonomical_rank)\n",
    "    \n",
    "    #-----------------\n",
    "    metrics = FI()\n",
    "    tabla_FI = pd.DataFrame.from_dict(metrics)\n",
    "    tabla_FI.to_csv(\"Results/FI_\"+name_type_model+'_'+taxonomical_rank+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-report",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "--------------------------\n",
    "# 37 variables Latent OTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='sigmoid')(in_layer)\n",
    "    net = layers.Dense(64, activation='sigmoid')(net)\n",
    "    net = layers.Dense(32, activation='sigmoid')(net)\n",
    "    net = layers.Dense(16, activation='sigmoid')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-professor",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37OTU\", \"Specie\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-revision",
   "metadata": {},
   "source": [
    "------------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37OTU\", \"Genus\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-worst",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37OTU\", \"Family\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-richards",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37OTU\", \"Order\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-motion",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37OTU\", \"Class\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-founder",
   "metadata": {},
   "source": [
    "----------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37OTU\", \"Phylum\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-question",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "--------------------------\n",
    "# 37 variables Latent Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='sigmoid')(in_layer)\n",
    "    net = layers.Dense(64, activation='sigmoid')(net)\n",
    "    net = layers.Dense(32, activation='sigmoid')(net)\n",
    "    net = layers.Dense(16, activation='sigmoid')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-startup",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37Combined\", \"Specie\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-construction",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37Combined\", \"Genus\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-civilian",
   "metadata": {},
   "source": [
    "----------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37Combined\", \"Family\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-spectacular",
   "metadata": {},
   "source": [
    "----------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37Combined\", \"Order\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-system",
   "metadata": {},
   "source": [
    "------------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37Combined\", \"Class\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-water",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"F_TOTAL\",\"F_CITMLB\",\"F_OTHER\",\"F_JUICE\",\"V_TOTAL\",\"V_DRKGR\",\"V_REDOR_TOTAL\",\"V_REDOR_TOMATO\",\"V_REDOR_OTHER\",\"V_STARCHY_TOTAL\",\"V_STARCHY_POTATO\",\"V_STARCHY_OTHER\",\"V_OTHER\",\\\n",
    "                     \"V_LEGUMES\",\"G_TOTAL\",\"G_WHOLE\",\"G_REFINED\",\"PF_TOTAL\",\"PF_MPS_TOTAL\",\"PF_MEAT\",\"PF_CUREDMEAT\",\"PF_ORGAN\",\"PF_POULT\",\"PF_SEAFD_HI\",\"PF_SEAFD_LOW\",\"PF_EGGS\",\"PF_SOY\",\"PF_NUTSDS\",\\\n",
    "                     \"PF_LEGUMES\",\"D_TOTAL\",\"D_MILK\",\"D_YOGURT\",\"D_CHEESE\",\"OILS\",\"SOLID_FATS\",\"ADD_SUGARS\",\"A_DRINKS\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"37Combined\", \"Phylum\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-speaking",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "# 22 variables Latent OTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='sigmoid')(in_layer)\n",
    "    net = layers.Dense(64, activation='sigmoid')(net)\n",
    "    net = layers.Dense(32, activation='sigmoid')(net)\n",
    "    net = layers.Dense(16, activation='sigmoid')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-option",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22OTU\", \"Specie\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-vinyl",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22OTU\", \"Genus\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-annual",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22OTU\", \"Family\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-painting",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22OTU\", \"Order\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-surface",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22OTU\", \"Class\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-government",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=96,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=None,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22OTU\", \"Phylum\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-rogers",
   "metadata": {},
   "source": [
    "-----------------\n",
    "-----------------\n",
    "# 22 variables Latent Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='relu')(in_layer)\n",
    "    net = layers.Dense(64, activation='relu')(net)\n",
    "    net = layers.Dense(32, activation='relu')(net)\n",
    "    net = layers.Dense(16, activation='relu')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-mercury",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22Combined\", \"Specie\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-march",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22Combined\", \"Genus\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-enclosure",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22Combined\", \"Family\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-builder",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22Combined\", \"Order\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-rochester",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22Combined\", \"Class\", data_microbioma_test, df_microbioma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-albuquerque",
   "metadata": {},
   "source": [
    "----------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = ['F_TOTAL', 'V_TOTAL', 'V_REDOR_TOTAL', 'V_STARCHY_TOTAL', 'V_LEGUMES', 'G_TOTAL', 'PF_TOTAL', 'PF_MEAT', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT','PF_SEAFD_HI', 'PF_SEAFD_LOW', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'D_TOTAL', 'D_YOGURT', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='FoodMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions, error per OTU and model FI\n",
    "save_data(encoder, model_latent, \"Food22Combined\", \"Phylum\", data_microbioma_test, df_microbioma_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
