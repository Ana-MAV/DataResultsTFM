{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "after-tuition",
   "metadata": {},
   "source": [
    "# Synthetic Diets\n",
    "We are going to see the microbiota predictions for 3 different diets: keto, vegetarian and mediterrean.\n",
    "\n",
    "We are going to predict with 4 models, teh best for each number of variables and latent space.\n",
    "\n",
    "We are going only to use nutritional values, not food variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Src/')\n",
    "from data_modificado import * \n",
    "from train_2 import * \n",
    "from transfer_learning import * \n",
    "from transfer_learning_FI import * \n",
    "from test_functions import *\n",
    "from layers import *\n",
    "from utils import *\n",
    "from loss import *\n",
    "from metric import *\n",
    "from results import *\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import itertools as it\n",
    "\n",
    "def read_df(\n",
    "              metadata_names=['age','Temperature','Precipitation3Days'],\n",
    "              random_state=42,\n",
    "              otu_filename='../Datasets/otu_table_all_80.csv',\n",
    "              metadata_filename='../Datasets/metadata_table_all_80.csv'):\n",
    "    otu = pd.read_csv(otu_filename, index_col=0, header=None).T\n",
    "    #print(otu.head())\n",
    "    otu = otu.set_index('otuids')\n",
    "    otu = otu.astype('int32')\n",
    "    metadata = pd.read_csv(metadata_filename)\n",
    "    #print(metadata.head())\n",
    "    metadata = metadata.set_index('X.SampleID')\n",
    "    metadata.head()\n",
    "    domain = metadata[metadata_names]\n",
    "    df = pd.concat([otu, domain], axis=1, sort=True, join='outer')\n",
    "    df_microbioma = df[otu.columns]\n",
    "    df_domain = df[domain.columns]\n",
    "    df_domain.head()\n",
    "    df_microbioma_train, df_microbioma_no_train, df_domain_train, df_domain_no_train = \\\n",
    "        train_test_split(df_microbioma, df_domain, test_size=0.1, random_state=random_state)\n",
    "    # Transfer learning subset\n",
    "    df_microbioma_test, df_microbioma_transfer_learning, df_domain_test, df_domain_transfer_learning = \\\n",
    "        train_test_split(df_microbioma_no_train, df_domain_no_train, test_size=0.1, random_state=random_state)\n",
    "    df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test = \\\n",
    "        train_test_split(df_microbioma_transfer_learning, df_domain_transfer_learning, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    return df_microbioma_train, df_microbioma_test, df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, df_domain_train, df_domain_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test, otu.columns, domain.columns\n",
    "\n",
    "def train_kfold_mod(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                batch_size, epochs, train_callbacks):\n",
    "    all_models = model_fn()\n",
    "    model, encoder_bioma, encoder_domain, decoder_bioma = all_models\n",
    "    metrics_prefix = None\n",
    "    if encoder_bioma is not None and encoder_domain is not None:\n",
    "        x_train = (m_train, d_train)\n",
    "        y_train = (m_train, m_train, z_train)\n",
    "        x_test = (m_test, d_test)\n",
    "        y_test = (m_test, m_test, z_test)\n",
    "    elif encoder_bioma is not None:\n",
    "        x_train = m_train\n",
    "        y_train = m_train\n",
    "        x_test = m_test\n",
    "        y_test = m_test\n",
    "        metrics_prefix = 'bioma'\n",
    "    elif encoder_domain is not None:\n",
    "        x_train = d_train\n",
    "        y_train = m_train\n",
    "        x_test = d_test\n",
    "        y_test = m_test\n",
    "        metrics_prefix = 'domain'\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(5000).batch(\n",
    "        batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    r = model.fit(train_dataset,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=val_dataset,\n",
    "                  callbacks=train_callbacks,\n",
    "                  verbose=0)\n",
    "    if metrics_prefix is not None:\n",
    "        old_keys = r.history\n",
    "        r.history = {}\n",
    "        for k, v in old_keys.items():\n",
    "            if k == 'loss' or k == 'val_loss':\n",
    "                new_key = k\n",
    "            elif k.startswith('val_'):\n",
    "                new_key = 'val_{}_{}'.format(metrics_prefix, k[4:])\n",
    "            else:\n",
    "                new_key = '{}_{}'.format(metrics_prefix, k)\n",
    "            r.history[new_key] = v\n",
    "    del val_dataset\n",
    "    del train_dataset\n",
    "    del x_train\n",
    "    del y_train\n",
    "    del x_test\n",
    "    del y_test\n",
    "    return r, all_models\n",
    "\n",
    "def train_2(model_fn,\n",
    "          data_microbioma,\n",
    "          data_domain,\n",
    "          latent_space=10,\n",
    "          folds=5,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          learning_rate_scheduler=ExpDecayScheluder(),\n",
    "          random_seed=347,\n",
    "          verbose=0):\n",
    "    data_zeros_latent = np.zeros((data_microbioma.shape[0], latent_space), dtype=data_microbioma.dtype)\n",
    "    results = []\n",
    "    models = []\n",
    "    train_callbacks = [\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=epochs + 1, restore_best_weights=True)]\n",
    "    if verbose >= 0:\n",
    "        train_callbacks += [TqdmCallback(verbose=verbose)]\n",
    "    if learning_rate_scheduler is not None:\n",
    "        train_callbacks += [learning_rate_scheduler.make()]\n",
    "\n",
    "    if folds <= 1:\n",
    "        m_train, m_test = data_microbioma, data_microbioma\n",
    "        d_train, d_test = data_domain, data_domain\n",
    "        z_train, z_test = data_zeros_latent, data_zeros_latent\n",
    "        tf.random.set_seed(random_seed)\n",
    "        r, m = train_kfold(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                           batch_size, epochs, train_callbacks)\n",
    "        results.append(r)\n",
    "        models.append(m)\n",
    "\n",
    "    else:\n",
    "        kf = KFold(n_splits=folds, random_state=random_seed, shuffle=True)\n",
    "        tf.random.set_seed(random_seed)\n",
    "\n",
    "        for train_index, test_index in kf.split(data_microbioma):\n",
    "            m_train, m_test = data_microbioma[train_index], data_microbioma[test_index]\n",
    "            if data_domain is None:\n",
    "                d_train, d_test = None, None\n",
    "            else:\n",
    "                d_train, d_test = data_domain[train_index], data_domain[test_index]\n",
    "            z_train, z_test = data_zeros_latent[train_index], data_zeros_latent[test_index]\n",
    "            r, m = train_kfold_mod(model_fn, m_train, d_train, z_train, m_test, d_test, z_test,\n",
    "                               batch_size, epochs, train_callbacks)\n",
    "            results.append(r)\n",
    "            models.append(m)\n",
    "    return results, models\n",
    "\n",
    "def perform_experiment_2_mod(cv_folds, epochs, batch_size, learning_rate, optimizer,\n",
    "                       learning_rate_scheduler, input_transform, output_transform,\n",
    "                       reconstruction_loss, latent_space, layers,\n",
    "                       activation, activation_latent,\n",
    "                       data_microbioma_train, data_domain_train,\n",
    "                       show_results=True, device='/CPU:0'): #Show results cambiado de False  aTrue\n",
    "    if input_transform is not None:\n",
    "        input_transform = input_transform()\n",
    "    #----------    \n",
    "    if output_transform is not None:\n",
    "        output_transform = output_transform()\n",
    "    #----------      \n",
    "    if reconstruction_loss.__class__.__name__ == 'MakeLoss':\n",
    "        reconstruction_loss = reconstruction_loss.make()\n",
    "    else:\n",
    "        reconstruction_loss = reconstruction_loss()\n",
    "    domain_layers = [l // 16 for l in layers] \n",
    "    bioma_autoencoder = \" -> \".join([\"b\"] +\n",
    "                                    [str(l) for l in layers] +\n",
    "                                    [str(latent_space)] +\n",
    "                                    [str(l) for l in reversed(layers)] +\n",
    "                                    [\"b\"])\n",
    "    #---------- \n",
    "    \n",
    "    if data_domain_train is not None:\n",
    "        domain_autoencoder = \" -> \".join([\"d\"] +\n",
    "                                     [str(l) for l in domain_layers] +\n",
    "                                     [str(latent_space)] +\n",
    "                                     [str(l) for l in reversed(layers)] +\n",
    "                                     [\"b\"])\n",
    "        \n",
    "    else: \n",
    "        domain_autoencoder = \" \"\n",
    "    #---------- \n",
    "    in_transform_name = input_transform.__class__.__name__ if input_transform else \"none\"\n",
    "    out_transform_name = output_transform.__class__.__name__ if output_transform else \"none\"\n",
    "    lr_scheduler_text = learning_rate_scheduler[\n",
    "        1] if learning_rate_scheduler is not None else \"none\"\n",
    "    lr_text = learning_rate if learning_rate_scheduler is not None else \"constant = {}\".format(\n",
    "        learning_rate)\n",
    "    learning_rate_scheduler = learning_rate_scheduler[\n",
    "        0] if learning_rate_scheduler is not None else None\n",
    "    optimizer = optimizer(learning_rate=learning_rate)\n",
    "    #---------- \n",
    "    experiment_parameters = [\n",
    "        (\"Input transform\", in_transform_name),\n",
    "        (\"Output transform\", out_transform_name),\n",
    "        (\"Reconstruction Loss\", reconstruction_loss.__class__.__name__),\n",
    "        (\"Latent Space\", latent_space),\n",
    "        (\"Bioma Autoencoder\", bioma_autoencoder),\n",
    "        (\"Domain Autoencoder\", domain_autoencoder),\n",
    "        (\"Activation Encoder\", activation),\n",
    "        (\"Activation Decoder\", activation),\n",
    "        (\"Activation Latent\", activation_latent),\n",
    "        (\"CV folds\", cv_folds),\n",
    "        (\"Epochs\", epochs),\n",
    "        (\"Batch Size\", batch_size),\n",
    "        (\"Learning Rate Scheduler\", lr_scheduler_text),\n",
    "        (\"Learning Rate\", lr_text),\n",
    "        (\"Optimizer\", optimizer.__class__.__name__),\n",
    "    ]\n",
    "    #----------  \n",
    "    if show_results:\n",
    "        md_text = \"\"\n",
    "        md_text += \"| Parameter             | Value         |\\n\"\n",
    "        md_text += \"|:----------------------|:--------------|\\n\"\n",
    "        for n, v in experiment_parameters:\n",
    "            md_text += \"| {} | {} |\\n\".format(n, v)\n",
    "\n",
    "        display(Markdown(md_text))\n",
    "    #------------\n",
    "    def create_model(print_data=False):\n",
    "        bioma_shape=data_microbioma_train.shape[1]\n",
    "        \n",
    "        if data_domain_train is not None:\n",
    "            domain_shape=data_domain_train.shape[1]\n",
    "        else:\n",
    "            domain_shape=None\n",
    "        models = autoencoder(bioma_shape=bioma_shape,\n",
    "                             domain_shape=domain_shape,\n",
    "                             output_shape=bioma_shape,\n",
    "                             latent_space=latent_space,\n",
    "                             bioma_layers=layers, \n",
    "                             domain_layers=domain_layers,\n",
    "                             input_transform=input_transform,\n",
    "                             output_transform=output_transform,\n",
    "                             activation_function_encoder=activation,\n",
    "                             activation_function_decoder=activation,\n",
    "                             activation_function_latent=activation_latent)\n",
    "\n",
    "        \n",
    "        model, encoder_bioma, encoder_domain, decoder_bioma = models\n",
    "\n",
    "        if print_data:\n",
    "            plot_models(model, encoder_bioma, encoder_domain, decoder_bioma)\n",
    "        compile_train(model,\n",
    "                      encoder_bioma=encoder_bioma,\n",
    "                      encoder_domain=encoder_domain,\n",
    "                      reconstruction_error=reconstruction_loss,\n",
    "                      encoded_comparison_error=losses.MeanAbsoluteError(),\n",
    "                      metrics=get_experiment_metrics(input_transform, output_transform),\n",
    "                      optimizer=optimizer)\n",
    "        return model, encoder_bioma, encoder_domain, decoder_bioma\n",
    "    #-----------\n",
    "    create_model(print_data=False)\n",
    "    #-----------\n",
    "    with tf.device(device):\n",
    "        results, models = train_2(create_model,\n",
    "                                data_microbioma_train,\n",
    "                                data_domain_train,\n",
    "                                latent_space=latent_space,\n",
    "                                folds=cv_folds,\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                learning_rate_scheduler=learning_rate_scheduler,\n",
    "                                verbose=-1)\n",
    "    #----------\n",
    "    validation_results = print_results(results, show_results=show_results)\n",
    "    if show_results:\n",
    "        display(Markdown(\"*************\"))\n",
    "\n",
    "    return experiment_parameters + validation_results, models, results\n",
    "\n",
    "#-----------------------------\n",
    "def save_predicted_otu_table_and_latent(pred,pred_latent,sample_names,otu_names,suffix=''):\n",
    "    df_otu = pd.DataFrame(pred, index=sample_names, columns=otu_names)\n",
    "    df_otu.T.to_csv('Results/otus_'+suffix+'.tsv', index=True, header=True, sep='\\t')\n",
    "\n",
    "    df_latent = pd.DataFrame(pred_latent, index=sample_names)\n",
    "    df_latent.T.to_csv('Results/latent_'+suffix+'.tsv', index=True, sep='\\t')\n",
    "    \n",
    "    return df_otu, df_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "dietas_nuevas = pd.read_csv(\"MetadataAdHocDiets.csv\",index_col='X.SampleID')\n",
    "dietas_nuevas.index.name = None\n",
    "dietas_nuevas = dietas_nuevas[nombres_metadatos]\n",
    "\n",
    "data_dietas_nuevas = dietas_nuevas.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-warning",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "-----------------------\n",
    "## 41 variables Latent OTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='softmax')(in_layer)\n",
    "    net = layers.Dense(64, activation='softmax')(net)\n",
    "    net = layers.Dense(32, activation='softmax')(net)\n",
    "    net = layers.Dense(16, activation='softmax')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-chicken",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes41AdHoc_Specie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-telephone",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes41AdHoc_Genus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-public",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes41AdHoc_Family')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-population",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes41AdHoc_Order')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-batman",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes41AdHoc_Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-chase",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes41AdHoc_Phylum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-mechanism",
   "metadata": {},
   "source": [
    "------------------\n",
    "------------------\n",
    "## 41 variables Latent Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='sigmoid')(in_layer)\n",
    "    net = layers.Dense(64, activation='sigmoid')(net)\n",
    "    net = layers.Dense(32, activation='sigmoid')(net)\n",
    "    net = layers.Dense(16, activation='sigmoid')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='softmax')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-example",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False, #True show results training, False doe not show it\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes41AdHoc_Specie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-scout",
   "metadata": {},
   "source": [
    "------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False, #True show results training, False doe not show it\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes41AdHoc_Genus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-assets",
   "metadata": {},
   "source": [
    "------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False, #True show results training, False doe not show it\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes41AdHoc_Family')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-disease",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False, #True show results training, False doe not show it\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes41AdHoc_Order')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-emerald",
   "metadata": {},
   "source": [
    "------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False, #True show results training, False doe not show it\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes41AdHoc_Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-watts",
   "metadata": {},
   "source": [
    "------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"KCAL\",\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"SUGR\",\"FIBE\",\"CALC\",\"IRON\",\"MAGN\",\"PHOS\",\"POTA\",\"SODI\",\"ZINC\",\"COPP\",\"SELE\",\"VC\",\"VB1\",\"VB2\",\"NIAC\",\"VB6\",\"FOLA\",\"VB12\",\"VARA\",\"RET\",\"BCAR\",\"ACAR\",\"CRYP\",\"LYCO\",\"LZ\",\"ATOC\",\"VK\",\"CHOLE\",\"SFAT\",\"MFAT\",\"PFAT\",\"VITD\",\"CHOLN\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='softmax',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False, #True show results training, False doe not show it\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes41AdHoc_Phylum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-creation",
   "metadata": {},
   "source": [
    "--------------------\n",
    "--------------------\n",
    "## 22 variables Latent OTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='sigmoid')(in_layer)\n",
    "    net = layers.Dense(64, activation='sigmoid')(net)\n",
    "    net = layers.Dense(32, activation='sigmoid')(net)\n",
    "    net = layers.Dense(16, activation='sigmoid')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-strand",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes22AdHoc_Specie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-honolulu",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes22AdHoc_Genus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-wallet",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes22AdHoc_Family')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-philippines",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes22AdHoc_Order')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-penny",
   "metadata": {},
   "source": [
    "---------------------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes22AdHoc_Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-gospel",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=True,\n",
    "                                                               device='/CPU:0')\n",
    "    \n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_OTUNutrientes22AdHoc_Phylum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-columbia",
   "metadata": {},
   "source": [
    "----------------\n",
    "----------------\n",
    "## 22 variables Latent Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def model_fn_latent():\n",
    "    in_layer = layers.Input(shape=(data_domain_train.shape[1],))\n",
    "    net = layers.Dense(128, activation='tanh')(in_layer)\n",
    "    net = layers.Dense(64, activation='tanh')(net)\n",
    "    net = layers.Dense(32, activation='tanh')(net)\n",
    "    net = layers.Dense(16, activation='tanh')(net)\n",
    "    out_layer = layers.Dense(latent_train.shape[1], activation='tanh')(net)\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-pricing",
   "metadata": {},
   "source": [
    "### Specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Specie.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes22AdHoc_Specie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-settlement",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Genus.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes22AdHoc_Genus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-plaza",
   "metadata": {},
   "source": [
    "------------\n",
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Family.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes22AdHoc_Family')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-bulgaria",
   "metadata": {},
   "source": [
    "------------\n",
    "### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Order.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes22AdHoc_Order')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-series",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Class.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes22AdHoc_Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-tampa",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_metadatos = [\"PROT\",\"TFAT\",\"CARB\",\"MOIS\",\"ALC\",\"CAFF\",\"THEO\",\"CALC\",\"MAGN\",\"POTA\",\"ZINC\",\"VC\",\"VB1\",\"VB6\",\"VARA\",\"ACAR\",\"CRYP\",\"LYCO\",\"ATOC\",\"VK\",\"CHOLE\",\"VITD\"]\n",
    "df_microbioma_train, df_microbioma_test, _, _, \\\n",
    "df_domain_train, df_domain_test, _, _, otu_columns, domain_columns = read_df(metadata_names=nombres_metadatos,otu_filename='otu_table_Phylum.csv',metadata_filename='NutrientMetadata.csv')\n",
    "\n",
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_test = df_microbioma_test.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)\n",
    "data_domain_test = df_domain_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metrics, models, results = perform_experiment_2_mod(cv_folds=0,\n",
    "                                                               epochs=100,\n",
    "                                                               batch_size=64,\n",
    "                                                               learning_rate=0.001,\n",
    "                                                               optimizer=optimizers.Adam,\n",
    "                                                               learning_rate_scheduler=None,\n",
    "                                                               input_transform=Percentage,\n",
    "                                                               output_transform=tf.keras.layers.Softmax,\n",
    "                                                               reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None),\n",
    "                                                               latent_space=15,\n",
    "                                                               layers=[512,256,128],\n",
    "                                                               activation='tanh',\n",
    "                                                               activation_latent='tanh',\n",
    "                                                               data_microbioma_train=data_microbioma_train,\n",
    "                                                               data_domain_train=data_domain_train,\n",
    "                                                               show_results=False,\n",
    "                                                               device='/CPU:0')\n",
    "\n",
    "#Save encoder and decoder\n",
    "model, encoder, _ ,decoder = models[0]\n",
    "    \n",
    "#predict latent space\n",
    "latent_train = encoder.predict(data_microbioma_train)\n",
    "\n",
    "#train the encoder\n",
    "result_latent, model_latent = train_tl_noEnsemble(model_fn_latent,\n",
    "                                                  latent_train,\n",
    "                                                  latent_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  data_domain_train,\n",
    "                                                  epochs=100,\n",
    "                                                  batch_size=16,\n",
    "                                                  verbose=-1)\n",
    "\n",
    "#evaluate the model\n",
    "latent_test = encoder.predict(data_microbioma_test)\n",
    "predictions = test_model_tl_noEnsemble(model_latent, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_test, data_domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_biome = encoder\n",
    "encoder_domain = model_latent\n",
    "\n",
    "pred_latent = encoder_domain.predict(data_dietas_nuevas)\n",
    "pred_domain = decoder.predict(pred_latent)\n",
    "\n",
    "df_pred_otu, df_pred_latent = save_predicted_otu_table_and_latent(pred_domain,pred_latent,dietas_nuevas.index,df_microbioma_test.columns,'predFromDomain_CombinedNutrientes22AdHoc_Phylum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
